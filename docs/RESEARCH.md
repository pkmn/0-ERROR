## AlphaGo

- [Playing Atari with Deep Reinforcement Learning](papers/deepmind-atari.pdf)
- [Move Evaluation in Go Using Deep Convolutional Neural Networks](papers/deepmind-alphago-dcnn.pdf)
- [Mastering the game of Go with deep neural networks and tree search](papers/deepmind-alphago.pdf)
- [Mastering the game of Go without human knowledge](https://www.nature.com/articles/nature24270.epdf)
- [Training Deep Convolutional Neural Networks to Play Go](papers/cnn-go.pdf)
- [Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](papers/deepmind-alphazero.pdf)
- [Lessons From Implementing AlphaZero](https://medium.com/oracledevs/7e36e9054191)
- [Better computer Go player with neural network and long-term prediction](papers/facebook-darkforest.pdf)
- [brilee/MuGo](https://github.com/brilee/MuGo)
- [tensorflow/minigo](https://github.com/tensorflow/minigo)
- [pytorch/ELF](https://github.com/pytorch/ELF)
- [leela-zero/leela-zero](https://github.com/leela-zero/leela-zero)
- [LeelaChessZero/lc0](https://github.com/LeelaChessZero/lc0)
- [suragnair/alpha-zero-general](https://github.com/suragnair/alpha-zero-general)
  - [Learning to Play Othello Without Human Knowledge](papers/othello.pdf)
  - [A Simple Alpha(Go) Zero Tutorial](https://web.stanford.edu/~surag/posts/alphazero.html)

## MCTS

- [A Survey of Monte Carlo Tree Search Methods](papers/mcts-survey.pdf)
- [Information Set Monte Carlo Tree Search](papers/information-set-mcts.pdf)
- [Multiple Tree for Partially Observable Monte-Carlo Tree Search](papers/multiple-pomcts.pdf)
- [Monte-Carlo Tree Search for the Simultaneous Move Game Tron](papers/tron-mcts.pdf)
- [Monte Carlo Tree Search for Simultaneous Move Games: A Case Study in the Game of Tron](papers/tron-mcts-casestudy.pdf)
- [Comparison of Different Selection Strategies in Monte-Carlo Tree Search for the Game of Tron](papers/tron-mcts-comparison.pdf)
- [Convergence of Monte Carlo Tree Search in Simultaneous Move Games](papers/simulataneous-mcts.pdf)
- [MCTS-Minimix Hybrids](papers/mcts-minimax.pdf)
- [jbradberry/mcts](https://github.com/jbradberry/mcts)
- [int8/monte-carlo-tree-search](https://github.com/int8/monte-carlo-tree-search)
  - [Monte Carlo Tree Search - beginners guide](https://int8.io/monte-carlo-tree-search-beginners-guide/)

### Parallel

- [Massively Parallel Monte Carlo Tree Search](papers/massively-parallel-mcts.pdf)
- [A New Method for Parallel Monte Carlo Tree Search](papers/parallel-mcts-new.pdf)
- [Parallel Monte Carlo Tree Search on GPU](papers/gpu-mcts.pdf)
- [Structured Parallel Programming for Monte Carlo Tree Search](papers/structured-parallel-mcts.pdf)
- [A Lock-free Multithreaded Monte-Carlo Tree Search Algorithm](papers/lockfree-mcts.pdf)
- [Scalable Distributed Monte-Carlo Tree Search](papers/distributed-mcts.pdf)

## Miscellaneous

- [Comparing UCT versus CFR in Simultaneous Games](papers/uct-vs-cfr.pdf)
- [Heads-up Limit Hold’em Poker is Solved](papers/poker-solved.pdf)
- [A Tutorial on Thomson Sampling](papers/thomson-sampling.pdf)
- [Introduction to Thompson Sampling: the Bernoulli bandit](https://gdmarmerola.github.io/ts-for-bernoulli-bandit/)
- [Finite-time Analysis of the Multiarmed Bandit Problem](papers/multiarmed-bandit.pdf)
- [Regret Minimization in Games with Incomplete Information (CFR)](https://nn.labml.ai/cfr/index.html)
- [The Multi-Armed Bandit Problem and Its Solutions](https://lilianweng.github.io/posts/2018-01-23-multi-armed-bandit/)
- [Regret Minimization in Games with Incomplete Information](papers/poker-regret.pdf)

## Pokémon

- [Future Sight AI](https://www.pokemonbattlepredictor.com/FSAI)
- [aturfah/poke2vec](https://github.com/aturfah/poke2vec)
  - [Poke2Vec: Vector Embeddings of Pokemon](https://aturfah.github.io/poke2vec/)
- [yuzeh/metagrok](https://github.com/yuzeh/metagrok)
  - [A Self-Play Policy Optimization Approach to Battling Pokemon](papers/pkmn-metagrok.pdf)
- [pmariglia/showdown](https://github.com/pmariglia/showdown)
- [davidstone/technical-machine](https://github.com/davidstone/technical-machine)
  - [Technical Machine](http://doublewise.net/pokemon/)
- [Optimal Battle Strategy in Pokemon using Reinforcement Learning](papers/pkmn-rl.pdf)
- [hsahovic/poke-env](https://github.com/hsahovic/poke-env)
- [dramamine/leftovers-again](https://github.com/dramamine/leftovers-again)
- [taylorhansen/pokemonshowdown-ai](https://github.com/taylorhansen/pokemonshowdown-ai)
- [blue-sky-sea/Pokemon-MCTS-AI-Master](https://github.com/blue-sky-sea/Pokemon-MCTS-AI-Master)
- [rameshvarun/showdownbot](https://github.com/rameshvarun/showdownbot)
  - [Percymon: A Pokemon Showdown Artificial Intelligence](papers/pkmn-percymon.pdf)
  